{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13815366,"sourceType":"datasetVersion","datasetId":8797413}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch torchvision scikit-learn pandas pillow tqdm openpyxl\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:20:25.290163Z","iopub.execute_input":"2025-11-30T18:20:25.290799Z","iopub.status.idle":"2025-11-30T18:21:43.228857Z","shell.execute_reply.started":"2025-11-30T18:20:25.290765Z","shell.execute_reply":"2025-11-30T18:21:43.228109Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install ftfy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:21:43.230286Z","iopub.execute_input":"2025-11-30T18:21:43.230529Z","iopub.status.idle":"2025-11-30T18:21:50.076430Z","shell.execute_reply.started":"2025-11-30T18:21:43.230506Z","shell.execute_reply":"2025-11-30T18:21:50.075720Z"}},"outputs":[{"name":"stdout","text":"Collecting ftfy\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m42.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy\nSuccessfully installed ftfy-6.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/dataset2\")\n\nimport os\nimport argparse\nfrom pathlib import Path\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\nfrom normalizer import normalize\n\n\nclass MemeDataset(Dataset):\n    def __init__(self, df, images_dir, tokenizer, max_length=128, image_size=224, use_normalizer=True):\n        self.df = df.reset_index(drop=True)\n        self.images_dir = Path(images_dir)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.image_size = image_size\n        self.use_normalizer = use_normalizer\n\n        self.transform = T.Compose([\n            T.Resize((image_size, image_size)),\n            T.ToTensor(),\n            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = self.images_dir / row['image_file_name']\n        try:\n            img = Image.open(img_path).convert('RGB')\n        except Exception:\n            img = Image.new('RGB', (self.image_size, self.image_size), color=(0, 0, 0))\n        img = self.transform(img)\n\n        text = str(row['text']) if pd.notna(row['text']) else \"\"\n\n        # Normalize text using the normalizer\n        if self.use_normalizer and text:\n            try:\n                text = normalize(text)\n            except Exception as e:\n                print(f\"Warning: Normalization failed for text at index {idx}: {e}\")\n                # Fall back to original text if normalization fails\n                pass\n\n        tok = self.tokenizer(text, truncation=True, padding='max_length',\n                             max_length=self.max_length, return_tensors='pt')\n        input_ids = tok['input_ids'].squeeze(0)\n        attention_mask = tok['attention_mask'].squeeze(0)\n\n        label = int(row['label'])\n        return {\n            'image': img,\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n\nclass MultimodalClassifier(nn.Module):\n    def __init__(self, text_model_name='csebuetnlp/banglishbert',\n                 num_labels=3, text_feat_dim=768, hidden_dim=512,\n                 dropout=0.2, freeze_text=False, freeze_image=False):\n        super().__init__()\n\n        # TEXT ENCODER (BanglishBERT)\n        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n        if freeze_text:\n            for p in self.text_encoder.parameters():\n                p.requires_grad = False\n\n        # Determine BERT hidden size\n        hidden_size = self.text_encoder.config.hidden_size\n\n        self.text_proj = nn.Linear(hidden_size, text_feat_dim)\n\n        # IMAGE ENCODER: ConvNeXt-Base\n        convnext = models.convnext_base(weights=models.ConvNeXt_Base_Weights.DEFAULT)\n        features = convnext.features\n        if freeze_image:\n            for p in features.parameters():\n                p.requires_grad = False\n\n        self.image_encoder = nn.Sequential(\n            *list(features.children()),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(1),\n        )\n\n        image_feat_dim = 1024  # ConvNeXt-Base has 1024 channels\n\n        self.image_proj = nn.Linear(image_feat_dim, image_feat_dim)\n\n        # CLASSIFIER HEAD\n        concat_dim = text_feat_dim + image_feat_dim\n        self.classifier = nn.Sequential(\n            nn.Linear(concat_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, num_labels),\n        )\n\n    def forward(self, input_ids, attention_mask, images):\n        text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n        if hasattr(text_out, 'pooler_output') and text_out.pooler_output is not None:\n            pooled = text_out.pooler_output\n        else:\n            last_hidden = text_out.last_hidden_state\n            mask = attention_mask.unsqueeze(-1).float()\n            summed = (last_hidden * mask).sum(1)\n            denom = mask.sum(1).clamp(min=1e-9)\n            pooled = summed / denom\n\n        txt_feat = self.text_proj(pooled)\n\n        img_feat = self.image_encoder(images)  # [B, 1024]\n        img_feat = self.image_proj(img_feat)\n\n        feat = torch.cat([txt_feat, img_feat], dim=1)\n        logits = self.classifier(feat)\n        return logits\n\n\ndef find_discrepancies(df, images_dir):\n    images_dir = Path(images_dir)\n    referenced = set(df['image_file_name'].astype(str).tolist())\n    actual = set([p.name for p in images_dir.glob('*') if p.is_file()])\n    missing = sorted(list(referenced - actual))\n    orphan = sorted(list(actual - referenced))\n    return missing, orphan\n\n\ndef prepare_dataframe(path, images_dir, drop_label_value=2):\n    df = pd.read_excel(path)\n    assert 'image_file_name' in df.columns and 'text' in df.columns and 'label' in df.columns, \\\n        \"metadata.xlsx must contain columns: image_file_name, text, label\"\n\n    df = df[df['label'] != drop_label_value].copy()\n    df['image_file_name'] = df['image_file_name'].astype(str).str.strip()\n\n    missing, orphan = find_discrepancies(df, images_dir)\n    if missing:\n        print(f\"Missing images for {len(missing)} metadata entries\")\n        df = df[~df['image_file_name'].isin(missing)].copy()\n\n    if orphan:\n        print(f\"Found {len(orphan)} orphan image files not in metadata:\")\n        for o in orphan[:20]:\n            print(\"  -\", o)\n        if len(orphan) > 20:\n            print(\"  ... and more\")\n\n    unique_labels = sorted(df['label'].unique().tolist())\n    label_map = {orig: idx for idx, orig in enumerate(unique_labels)}\n    df['label'] = df['label'].map(label_map)\n    print(\"Label mapping:\", label_map)\n    return df, orphan, label_map\n\n\ndef compute_class_weights(df):\n    counts = df['label'].value_counts().sort_index().values\n    weights = 1.0 / counts\n    sample_weights = df['label'].map(lambda x: weights[x]).values\n    return sample_weights\n\n\ndef collate_fn(batch):\n    images = torch.stack([b['image'] for b in batch])\n    input_ids = torch.stack([b['input_ids'] for b in batch])\n    attention_mask = torch.stack([b['attention_mask'] for b in batch])\n    labels = torch.stack([b['label'] for b in batch])\n    return {\n        'image': images,\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'labels': labels\n    }\n\n\ndef train_one_epoch(model, dataloader, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    total_correct = 0\n    total_examples = 0\n    criterion = nn.CrossEntropyLoss()\n    for batch in tqdm(dataloader, desc=\"Train\"):\n        images = batch['image'].to(device)\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        batch_size = labels.size(0)\n        total_loss += loss.item() * batch_size\n\n        preds = torch.argmax(logits, dim=1)\n        total_correct += (preds == labels).sum().item()\n        total_examples += batch_size\n\n    train_loss = total_loss / total_examples\n    train_acc = total_correct / total_examples\n    return train_loss, train_acc\n\n\n@torch.no_grad()\ndef evaluate(model, dataloader, device, label_map):\n    model.eval()\n    preds = []\n    trues = []\n    total_loss = 0.0\n    criterion = nn.CrossEntropyLoss()\n    for batch in tqdm(dataloader, desc=\"Eval\"):\n        images = batch['image'].to(device)\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n        loss = criterion(logits, labels)\n        batch_size = labels.size(0)\n        total_loss += loss.item() * batch_size\n\n        batch_preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n        batch_trues = labels.cpu().numpy().tolist()\n        preds.extend(batch_preds)\n        trues.extend(batch_trues)\n\n    acc = accuracy_score(trues, preds)\n    val_loss = total_loss / len(trues)\n    report = classification_report(trues, preds, digits=4)\n    return acc, val_loss, report, trues, preds\n\n\ndef main(args):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"Device:\", device)\n\n    df, orphan_files, label_map = prepare_dataframe(args.data, args.images_dir, drop_label_value=2)\n\n    if args.delete_orphans and orphan_files:\n        for fname in orphan_files:\n            p = Path(args.images_dir) / fname\n            try:\n                p.unlink()\n            except Exception as e:\n                print(\"Could not delete:\", p, e)\n        print(\"Deleted orphans.\")\n\n    train_df, test_df = train_test_split(df, test_size=args.test_size, stratify=df['label'], random_state=42)\n    train_df, val_df = train_test_split(train_df, test_size=args.val_size, stratify=train_df['label'], random_state=42)\n    print(\"Train / Val / Test sizes:\", len(train_df), len(val_df), len(test_df))\n\n    tokenizer = AutoTokenizer.from_pretrained(args.text_model)\n\n    use_normalizer = not args.disable_normalizer\n    if use_normalizer:\n        print(\"Text normalization enabled\")\n    else:\n        print(\"Text normalization disabled\")\n\n    train_dataset = MemeDataset(train_df, args.images_dir, tokenizer,\n                                max_length=args.max_length, image_size=args.image_size,\n                                use_normalizer=use_normalizer)\n    val_dataset = MemeDataset(val_df, args.images_dir, tokenizer,\n                              max_length=args.max_length, image_size=args.image_size,\n                              use_normalizer=use_normalizer)\n    test_dataset = MemeDataset(test_df, args.images_dir, tokenizer,\n                               max_length=args.max_length, image_size=args.image_size,\n                               use_normalizer=use_normalizer)\n\n    sample_weights = compute_class_weights(train_df)\n    sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)\n\n    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=sampler, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    num_labels = len(label_map)\n    model = MultimodalClassifier(text_model_name=args.text_model,\n                                 num_labels=num_labels,\n                                 text_feat_dim=args.text_feat_dim,\n                                 hidden_dim=args.hidden_dim,\n                                 dropout=args.dropout,\n                                 freeze_text=args.freeze_text,\n                                 freeze_image=args.freeze_image)\n    model.to(device)\n\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n\n    best_val_acc = 0.0\n    os.makedirs(args.out_dir, exist_ok=True)\n\n    for epoch in range(1, args.epochs + 1):\n        print(f\"Epoch {epoch}/{args.epochs}\")\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n\n        val_acc, val_loss, val_report, _, _ = evaluate(model, val_loader, device, label_map)\n        print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.4f}\")\n        print(\"Validation report:\\n\", val_report)\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({'model_state_dict': model.state_dict(), 'label_map': label_map},\n                       os.path.join(args.out_dir, \"best_model.pt\"))\n            print(\"Saved best model.\")\n\n    print(\"Testing best model …\")\n    ckpt = torch.load(os.path.join(args.out_dir, \"best_model.pt\"), map_location=device)\n    model.load_state_dict(ckpt['model_state_dict'])\n\n    # Correct unpacking for updated evaluate()\n    test_acc, test_loss, test_report, trues, preds = evaluate(model, test_loader, device, label_map)\n    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n    print(\"Test report:\\n\", test_report)\n    print(\"Len(trues) =\", len(trues), \"Len(preds) =\", len(preds))\n\n    # Build reverse label map (used for plotting and mapping back)\n    inv_map = {v: k for k, v in label_map.items()}\n\n    # Check non-empty\n    if len(trues) == 0 or len(preds) == 0:\n        print(\"No predictions or no true labels to build confusion matrix.\")\n    else:\n        # ---- Confusion Matrix ----\n        cm = confusion_matrix(trues, preds)\n\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(\n            cm,\n            annot=True,\n            fmt='d',\n            cmap='Blues',\n            xticklabels=[inv_map[i] for i in sorted(inv_map.keys())],\n            yticklabels=[inv_map[i] for i in sorted(inv_map.keys())]\n        )\n        plt.xlabel(\"Predicted Label\")\n        plt.ylabel(\"True Label\")\n        plt.title(\"Confusion Matrix (Color Heatmap)\")\n        plt.tight_layout()\n\n        out_path = os.path.join(args.out_dir, \"confusion_matrix.png\")\n        plt.savefig(out_path)   # save first\n        try:\n            plt.show()          # then show in notebook (Option A)\n        except Exception:\n            # in non-interactive env this may fail silently; we already saved the figure\n            pass\n        plt.close()\n        print(\"Confusion Matrix saved to:\", out_path)\n\n    # Save predictions CSV\n    out = test_df.reset_index(drop=True).copy()\n    out['pred_idx'] = preds\n    out['pred_orig'] = out['pred_idx'].map(inv_map)\n    out.to_csv(os.path.join(args.out_dir, \"test_predictions.csv\"), index=False)\n    print(\"Saved test predictions to\", os.path.join(args.out_dir, \"test_predictions.csv\"))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data', type=str, default='/kaggle/input/dataset2/metadata.xlsx')\n    parser.add_argument('--images_dir', type=str, default='/kaggle/input/dataset2/images')\n    parser.add_argument('--out_dir', type=str, default='/kaggle/working/output')\n    parser.add_argument('--epochs', type=int, default=7)\n    parser.add_argument('--batch_size', type=int, default=16)\n    parser.add_argument('--lr', type=float, default=2e-5)\n    parser.add_argument('--text_model', type=str, default='csebuetnlp/banglishbert')\n    parser.add_argument('--max_length', type=int, default=64)\n    parser.add_argument('--image_size', type=int, default=224)\n    parser.add_argument('--val_size', type=float, default=0.1)\n    parser.add_argument('--test_size', type=float, default=0.1)\n    parser.add_argument('--text_feat_dim', type=int, default=768)  # match BERT hidden\n    parser.add_argument('--hidden_dim', type=int, default=512)\n    parser.add_argument('--dropout', type=float, default=0.2)\n    parser.add_argument('--freeze_text', action='store_true')\n    parser.add_argument('--freeze_image', action='store_true')\n    parser.add_argument('--delete-orphans', action='store_true')\n    parser.add_argument('--disable-normalizer', action='store_true',\n                        help='Disable text normalization (enabled by default)')\n\n    args = parser.parse_args([])\n    main(args)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:21:50.077608Z","iopub.execute_input":"2025-11-30T18:21:50.077810Z","iopub.status.idle":"2025-11-30T19:26:41.145185Z","shell.execute_reply.started":"2025-11-30T18:21:50.077789Z","shell.execute_reply":"2025-11-30T19:26:41.144456Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nFound 4 orphan image files not in metadata:\n  - FB_IMG_1751540473613.jpg\n  - FB_IMG_1751739942837.jpg\n  - FB_IMG_1754929300743.jpg\n  - FB_IMG_1755921270397.jpg\nLabel mapping: {0: 0, 1: 1, 3: 2}\nTrain / Val / Test sizes: 5508 612 680\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3454cfec544e35b24fe9977b8db813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab5504c986c448fb1ef7294f2ab33bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eeef3a10f8c499d8bcfdae6739cdf7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a08cdd64dc49fe93c5432b50a7ee44"}},"metadata":{}},{"name":"stdout","text":"Text normalization enabled\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-30 18:22:25.509481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764526945.718125      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764526945.777607      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe17dcc60f51401d88584af30c2119e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d224ece888174322a5e6958f4bbae22a"}},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n100%|██████████| 338M/338M [00:01<00:00, 193MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:41<00:00,  1.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9212 | Train Acc: 0.5534\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:25<00:00,  1.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.8745 | Validation Acc: 0.6471\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.7193    0.2384    0.3581       172\n           1     0.5148    0.6591    0.5781       132\n           2     0.6943    0.8701    0.7723       308\n\n    accuracy                         0.6471       612\n   macro avg     0.6428    0.5892    0.5695       612\nweighted avg     0.6626    0.6471    0.6140       612\n\nSaved best model.\nEpoch 2/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:41<00:00,  1.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5894 | Train Acc: 0.7741\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.9405 | Validation Acc: 0.6520\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.6893    0.4128    0.5164       172\n           1     0.5287    0.6288    0.5744       132\n           2     0.6960    0.7955    0.7424       308\n\n    accuracy                         0.6520       612\n   macro avg     0.6380    0.6123    0.6111       612\nweighted avg     0.6580    0.6520    0.6426       612\n\nSaved best model.\nEpoch 3/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:37<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3693 | Train Acc: 0.8680\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.0742 | Validation Acc: 0.6471\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.6063    0.4477    0.5151       172\n           1     0.5267    0.5985    0.5603       132\n           2     0.7164    0.7792    0.7465       308\n\n    accuracy                         0.6471       612\n   macro avg     0.6165    0.6085    0.6073       612\nweighted avg     0.6445    0.6471    0.6413       612\n\nEpoch 4/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:36<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2303 | Train Acc: 0.9259\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.1677 | Validation Acc: 0.6422\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.5778    0.4535    0.5081       172\n           1     0.6383    0.4545    0.5310       132\n           2     0.6658    0.8279    0.7381       308\n\n    accuracy                         0.6422       612\n   macro avg     0.6273    0.5787    0.5924       612\nweighted avg     0.6351    0.6422    0.6288       612\n\nEpoch 5/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:38<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1401 | Train Acc: 0.9562\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.4384 | Validation Acc: 0.6650\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.7536    0.3023    0.4315       172\n           1     0.5600    0.6364    0.5957       132\n           2     0.6896    0.8799    0.7732       308\n\n    accuracy                         0.6650       612\n   macro avg     0.6677    0.6062    0.6002       612\nweighted avg     0.6796    0.6650    0.6389       612\n\nSaved best model.\nEpoch 6/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:36<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1144 | Train Acc: 0.9664\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.3735 | Validation Acc: 0.6601\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.6142    0.4535    0.5217       172\n           1     0.5852    0.5985    0.5918       132\n           2     0.7057    0.8019    0.7508       308\n\n    accuracy                         0.6601       612\n   macro avg     0.6350    0.6180    0.6214       612\nweighted avg     0.6540    0.6601    0.6521       612\n\nEpoch 7/7\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 345/345 [08:35<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0832 | Train Acc: 0.9759\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 39/39 [00:23<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 1.5552 | Validation Acc: 0.6536\nValidation report:\n               precision    recall  f1-score   support\n\n           0     0.6635    0.4012    0.5000       172\n           1     0.6036    0.5076    0.5514       132\n           2     0.6650    0.8571    0.7489       308\n\n    accuracy                         0.6536       612\n   macro avg     0.6440    0.5886    0.6001       612\nweighted avg     0.6513    0.6536    0.6364       612\n\nTesting best model …\n","output_type":"stream"},{"name":"stderr","text":"Eval: 100%|██████████| 43/43 [00:30<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 1.5078 | Test Acc: 0.6324\nTest report:\n               precision    recall  f1-score   support\n\n           0     0.6200    0.3246    0.4261       191\n           1     0.5380    0.5822    0.5592       146\n           2     0.6706    0.8251    0.7399       343\n\n    accuracy                         0.6324       680\n   macro avg     0.6095    0.5773    0.5751       680\nweighted avg     0.6279    0.6324    0.6130       680\n\nLen(trues) = 680 Len(preds) = 680\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Confusion Matrix saved to: /kaggle/working/output/confusion_matrix.png\nSaved test predictions to /kaggle/working/output/test_predictions.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncm = confusion_matrix(trues, preds)\n\nplt.figure(figsize=(7,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T19:26:41.147000Z","iopub.execute_input":"2025-11-30T19:26:41.147248Z","iopub.status.idle":"2025-11-30T19:26:41.331630Z","shell.execute_reply.started":"2025-11-30T19:26:41.147231Z","shell.execute_reply":"2025-11-30T19:26:41.330677Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2528077188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trues' is not defined"],"ename":"NameError","evalue":"name 'trues' is not defined","output_type":"error"}],"execution_count":4}]}