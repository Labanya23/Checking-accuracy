{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T10:35:07.270712Z",
     "iopub.status.busy": "2025-11-24T10:35:07.270157Z",
     "iopub.status.idle": "2025-11-24T10:36:19.115406Z",
     "shell.execute_reply": "2025-11-24T10:36:19.114408Z",
     "shell.execute_reply.started": "2025-11-24T10:35:07.270684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchvision scikit-learn pandas pillow tqdm openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T10:36:19.117595Z",
     "iopub.status.busy": "2025-11-24T10:36:19.117123Z",
     "iopub.status.idle": "2025-11-24T10:36:25.126787Z",
     "shell.execute_reply": "2025-11-24T10:36:25.126087Z",
     "shell.execute_reply.started": "2025-11-24T10:36:19.117568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T10:36:25.128304Z",
     "iopub.status.busy": "2025-11-24T10:36:25.128067Z",
     "iopub.status.idle": "2025-11-24T11:56:07.573966Z",
     "shell.execute_reply": "2025-11-24T11:56:07.572470Z",
     "shell.execute_reply.started": "2025-11-24T10:36:25.128281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-11-24 10:36:41.322516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763980601.500174      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763980601.553024      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}\n",
      "Train / Val / Test sizes: 5510 / 613 / 681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5808472743dd451e8be10c81199bcca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e400d81d40a42e3ba68bc8f44f9c6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de71f224c0e7490abecaeb9ddf17d7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1e243b80cc44b189e324ace1e1e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c099943cea89478ba40e02ab1f6dfb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3244f1f71e42418819750984c7eb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb24eb137a94e7a84c171c47702f01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb2baac17f34cf29bd268c719d87061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8ae209fa4945d8923211289b4eb73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c7cde67c9d479b93281d909968f33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ada788f8ec0487aa7bd42dfce1905a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.132968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5612\n",
      "✓ Saved best model (val_acc: 0.5612)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.830880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5530\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.551097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5465\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.312597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5449\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.177263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5285\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.125016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5122\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.097969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5498\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.069008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5334\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.041195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5188\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.040054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5285\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/4255686873.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'freeze_image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_48/4255686873.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded model from epoch {ckpt.get('epoch', '?')} with val_acc: {ckpt.get('val_acc', 0):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/dataset59\")  \n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import timm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "try:\n",
    "    from normalizer import normalize\n",
    "except Exception:\n",
    "    def normalize(x): \n",
    "        return x  \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, tokenizer=None, max_length=128, image_size=224,\n",
    "                 use_normalizer=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.tokenizer = tokenizer  \n",
    "        self.max_length = max_length\n",
    "        self.image_size = image_size\n",
    "        self.use_normalizer = use_normalizer\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        img_path = self.images_dir / row['image_file_name']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            \n",
    "            img = Image.new('RGB', (self.image_size, self.image_size), color=(0, 0, 0))\n",
    "        img = self.transform(img)\n",
    "\n",
    "        text = clean_text(row.get('text', \"\"))\n",
    "\n",
    "        if self.use_normalizer and text:\n",
    "            try:\n",
    "                text = normalize(text)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        input_ids = torch.zeros(self.max_length, dtype=torch.long)\n",
    "        attention_mask = torch.zeros(self.max_length, dtype=torch.long)\n",
    "\n",
    "        label = int(row['label'])\n",
    "        return {\n",
    "            'image': img,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([b['image'] for b in batch])\n",
    "    input_ids = torch.stack([b['input_ids'] for b in batch])\n",
    "    attention_mask = torch.stack([b['attention_mask'] for b in batch])\n",
    "    labels = torch.stack([b['label'] for b in batch])\n",
    "    texts = [b['text'] for b in batch]\n",
    "    return {\n",
    "        'image': images,\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels,\n",
    "        'texts': texts\n",
    "    }\n",
    "\n",
    "\n",
    "class MultimodalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvNeXt base image encoder + SentenceTransformer text encoder fusion classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 sentence_model_name: str,\n",
    "                 image_model_name: str = \"convnext_base\",\n",
    "                 proj_dim: int = 512,\n",
    "                 num_labels: int = 2,\n",
    "                 freeze_image: bool = False,\n",
    "                 freeze_text: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # SentenceTransformer text encoder\n",
    "        self.text_encoder = SentenceTransformer(sentence_model_name)\n",
    "        raw_text_dim = self.text_encoder.get_sentence_embedding_dimension()\n",
    "\n",
    "        if freeze_text:\n",
    "            for p in self.text_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.text_proj = nn.Linear(raw_text_dim, proj_dim)\n",
    "\n",
    "        # Image encoder (ConvNeXt from timm)\n",
    "        self.image_encoder = timm.create_model(image_model_name, pretrained=True, num_classes=0)\n",
    "        image_feat_dim = self.image_encoder.num_features\n",
    "\n",
    "        if freeze_image:\n",
    "            for p in self.image_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.image_proj = nn.Linear(image_feat_dim, proj_dim)\n",
    "\n",
    "        # Classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(proj_dim * 2, proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(proj_dim, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, texts):\n",
    "        \"\"\"\n",
    "        images: tensor [B, C, H, W]\n",
    "        texts: list[str] of length B\n",
    "        \"\"\"\n",
    "        # IMAGE: get features and project\n",
    "        img_feat = self.image_encoder(images)           \n",
    "        img_feat = self.image_proj(img_feat)            \n",
    "\n",
    "        \n",
    "        txt_feat = self.text_encoder.encode(texts, convert_to_tensor=True)  \n",
    "        # move to same device as image features\n",
    "        if txt_feat.device != img_feat.device:\n",
    "            txt_feat = txt_feat.to(img_feat.device)\n",
    "        txt_feat = self.text_proj(txt_feat)             \n",
    "\n",
    "        # CONCAT + CLASSIFY\n",
    "        fused = torch.cat([img_feat, txt_feat], dim=1)  \n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def find_discrepancies(df, images_dir):\n",
    "    images_dir = Path(images_dir)\n",
    "    referenced = set(df['image_file_name'].astype(str).tolist())\n",
    "    actual = set([p.name for p in images_dir.glob('*') if p.is_file()])\n",
    "    missing = sorted(list(referenced - actual))\n",
    "    orphan = sorted(list(actual - referenced))\n",
    "    return missing, orphan\n",
    "\n",
    "\n",
    "def prepare_dataframe(path, images_dir, drop_label_value=None):\n",
    "    df = pd.read_excel(path)\n",
    "    required_cols = {'image_file_name', 'text', 'label'}\n",
    "    if not required_cols.issubset(set(df.columns)):\n",
    "        raise AssertionError(f\"metadata.xlsx must contain columns: {required_cols}\")\n",
    "\n",
    "    if drop_label_value is not None:\n",
    "        df = df[df['label'] != drop_label_value].copy()\n",
    "\n",
    "    df['image_file_name'] = df['image_file_name'].astype(str).str.strip()\n",
    "\n",
    "    missing, orphan = find_discrepancies(df, images_dir)\n",
    "    if missing:\n",
    "        print(f\"Missing images for {len(missing)} metadata entries; these rows will be dropped.\")\n",
    "        df = df[~df['image_file_name'].isin(missing)].copy()\n",
    "\n",
    "    if orphan:\n",
    "        print(f\"Found {len(orphan)} orphan image files not in metadata (showing up to 20):\")\n",
    "        for o in orphan[:20]:\n",
    "            print(\"  -\", o)\n",
    "        if len(orphan) > 20:\n",
    "            print(\"  ... and more\")\n",
    "\n",
    "    unique_labels = sorted(df['label'].unique().tolist())\n",
    "    label_map = {orig: idx for idx, orig in enumerate(unique_labels)}\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "    print(\"Label mapping:\", label_map)\n",
    "    return df, orphan, label_map\n",
    "\n",
    "\n",
    "def compute_sample_weights(df, power=0.5):\n",
    "    counts = df['label'].value_counts().sort_index().values\n",
    "    # avoid division by zero\n",
    "    counts = np.maximum(counts, 1)\n",
    "    weights = (1.0 / counts) ** power\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    sample_weights = df['label'].map(lambda x: weights[x]).values\n",
    "    return sample_weights\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(dataloader, desc=\"Train\", leave=False):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        texts = batch['texts']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images=images, texts=texts)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, label_map):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for batch in tqdm(dataloader, desc=\"Eval\", leave=False):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        texts = batch['texts']\n",
    "\n",
    "        logits = model(images=images, texts=texts)\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
    "        batch_trues = labels.cpu().numpy().tolist()\n",
    "        preds.extend(batch_preds)\n",
    "        trues.extend(batch_trues)\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    report = classification_report(trues, preds, digits=4)\n",
    "    cm = confusion_matrix(trues, preds)\n",
    "    return acc, report, trues, preds, cm\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    df, orphan_files, label_map = prepare_dataframe(args.data, args.images_dir, drop_label_value=args.drop_label_value)\n",
    "\n",
    "    if args.delete_orphans and orphan_files:\n",
    "        for fname in orphan_files:\n",
    "            p = Path(args.images_dir) / fname\n",
    "            try:\n",
    "                p.unlink()\n",
    "            except Exception as e:\n",
    "                print(\"Could not delete:\", p, e)\n",
    "        print(\"Deleted orphans.\")\n",
    "\n",
    "    # splits\n",
    "    train_df, test_df = train_test_split(df, test_size=args.test_size, stratify=df['label'], random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=args.val_size, stratify=train_df['label'], random_state=42)\n",
    "    print(f\"Train / Val / Test sizes: {len(train_df)} / {len(val_df)} / {len(test_df)}\")\n",
    "\n",
    "    # Datasets & Dataloaders\n",
    "    tokenizer = None  # not needed for SentenceTransformer; kept for compatibility\n",
    "    train_dataset = MemeDataset(train_df, args.images_dir, tokenizer, max_length=args.max_length,\n",
    "                                image_size=args.image_size, use_normalizer=not args.disable_normalizer)\n",
    "    val_dataset = MemeDataset(val_df, args.images_dir, tokenizer, max_length=args.max_length,\n",
    "                              image_size=args.image_size, use_normalizer=not args.disable_normalizer)\n",
    "    test_dataset = MemeDataset(test_df, args.images_dir, tokenizer, max_length=args.max_length,\n",
    "                               image_size=args.image_size, use_normalizer=not args.disable_normalizer)\n",
    "\n",
    "    sample_weights = compute_sample_weights(train_df, power=args.weight_power)\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=sampler,\n",
    "                              collate_fn=collate_fn, num_workers=args.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                            collate_fn=collate_fn, num_workers=args.num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                             collate_fn=collate_fn, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    num_labels = len(label_map)\n",
    "    model = MultimodalClassifier(sentence_model_name=args.sentence_model,\n",
    "                                 image_model_name=args.image_model,\n",
    "                                 proj_dim=args.proj_dim,\n",
    "                                 num_labels=num_labels,\n",
    "                                 freeze_image=args.freeze_image,\n",
    "                                 freeze_text=args.freeze_text)\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss, optimizer, scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                  lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * args.epochs\n",
    "    warmup_steps = int(0.1 * total_steps) if total_steps > 0 else 0\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{args.epochs}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, scheduler)\n",
    "        print(f\"Train loss: {train_loss:.6f}\")\n",
    "\n",
    "        val_acc, val_report, _, _, val_cm = evaluate(model, val_loader, device, label_map)\n",
    "        print(f\"Validation Acc: {val_acc:.4f}\")\n",
    "        if args.verbose:\n",
    "            print(\"Validation report:\\n\", val_report)\n",
    "            print(\"Validation confusion matrix:\\n\", val_cm)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'label_map': label_map,\n",
    "                'epoch': epoch,\n",
    "                'val_acc': val_acc\n",
    "            }, os.path.join(args.out_dir, \"best_model.pt\"))\n",
    "            print(f\"✓ Saved best model (val_acc: {val_acc:.4f})\")\n",
    "\n",
    "    # final evaluation on test\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*60)\n",
    "    ckpt_path = os.path.join(args.out_dir, \"best_model.pt\")\n",
    "    if os.path.exists(ckpt_path):\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "        print(f\"Loaded model from epoch {ckpt.get('epoch', '?')} with val_acc: {ckpt.get('val_acc', 0):.4f}\")\n",
    "    else:\n",
    "        print(\"No checkpoint found, using current model weights.\")\n",
    "\n",
    "    test_acc, test_report, trues, preds, test_cm = evaluate(model, test_loader, device, label_map)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(test_report)\n",
    "    print(\"\\nTest Confusion Matrix:\")\n",
    "    print(test_cm)\n",
    "\n",
    "    # Save predictions CSV\n",
    "    out = test_df.reset_index(drop=True).copy()\n",
    "    out['pred_idx'] = preds\n",
    "    inv_map = {v: k for k, v in label_map.items()}\n",
    "    out['pred_orig'] = out['pred_idx'].map(inv_map)\n",
    "    out['true_orig'] = out['label'].map(inv_map)\n",
    "    out.to_csv(os.path.join(args.out_dir, \"test_predictions.csv\"), index=False)\n",
    "    print(f\"\\nResults saved to {args.out_dir}/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', type=str, default='/kaggle/input/dataset59/metadata.xlsx')\n",
    "    parser.add_argument('--images_dir', type=str, default='/kaggle/input/dataset59/images')\n",
    "    parser.add_argument('--out_dir', type=str, default='/kaggle/working/output')\n",
    "    parser.add_argument('--epochs', type=int, default=10)    \n",
    "    parser.add_argument('--batch_size', type=int, default=10)         \n",
    "    parser.add_argument('--lr', type=float, default=2e-5)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.005)\n",
    "    parser.add_argument('--sentence_model', type=str,\n",
    "                        default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    parser.add_argument('--image_model', type=str, default='convnext_base')\n",
    "    parser.add_argument('--proj_dim', type=int, default=512)\n",
    "    parser.add_argument('--max_length', type=int, default=128)\n",
    "    parser.add_argument('--image_size', type=int, default=224)\n",
    "    parser.add_argument('--val_size', type=float, default=0.1)\n",
    "    parser.add_argument('--test_size', type=float, default=0.1)\n",
    "    parser.add_argument('--drop_label_value', type=int, default=None,\n",
    "                        help='If you want to drop a specific label value from metadata (optional)')\n",
    "    parser.add_argument('--weight_power', type=float, default=0.5)\n",
    "    parser.add_argument('--freeze_text', action='store_true')\n",
    "    parser.add_argument('--freeze_image', action='store_true')\n",
    "    parser.add_argument('--delete_orphans', action='store_true')\n",
    "    parser.add_argument('--disable_normalizer', action='store_true', dest='disable_normalizer')\n",
    "    parser.add_argument('--num_workers', type=int, default=0)\n",
    "    parser.add_argument('--verbose', action='store_true')\n",
    "\n",
    "    \n",
    "    parser.add_argument('--delete-orphans', dest='delete_orphans', action='store_true')\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    \n",
    "    \n",
    "    args.delete_orphans = getattr(args, 'delete_orphans', False)\n",
    "    args.disable_normalizer = getattr(args, 'disable_normalizer', False)\n",
    "    args.freeze_text = getattr(args, 'freeze_text', False)\n",
    "    args.freeze_image = getattr(args, 'freeze_image', False)\n",
    "\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8815892,
     "sourceId": 13841532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
