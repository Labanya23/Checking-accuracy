{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T05:19:30.253744Z",
     "iopub.status.busy": "2025-11-24T05:19:30.253473Z",
     "iopub.status.idle": "2025-11-24T05:20:44.848993Z",
     "shell.execute_reply": "2025-11-24T05:20:44.848249Z",
     "shell.execute_reply.started": "2025-11-24T05:19:30.253722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchvision scikit-learn pandas pillow tqdm openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T05:20:44.850645Z",
     "iopub.status.busy": "2025-11-24T05:20:44.850413Z",
     "iopub.status.idle": "2025-11-24T05:20:48.236349Z",
     "shell.execute_reply": "2025-11-24T05:20:48.235415Z",
     "shell.execute_reply.started": "2025-11-24T05:20:44.850620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T05:20:48.238364Z",
     "iopub.status.busy": "2025-11-24T05:20:48.237793Z",
     "iopub.status.idle": "2025-11-24T06:23:09.029557Z",
     "shell.execute_reply": "2025-11-24T06:23:09.028070Z",
     "shell.execute_reply.started": "2025-11-24T05:20:48.238337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-11-24 05:21:06.632183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763961666.843308      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763961666.902128      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Found 4 orphan image files not in metadata (showing up to 20):\n",
      "  - FB_IMG_1751540473613.jpg\n",
      "  - FB_IMG_1751739942837.jpg\n",
      "  - FB_IMG_1754929300743.jpg\n",
      "  - FB_IMG_1755921270397.jpg\n",
      "Label mapping: {0: 0, 1: 1, 3: 2}\n",
      "Train / Val / Test sizes: 5508 / 612 / 680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8312b429a744be3b6b0ac937298f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0936287f912a44baadcbb8a2a99ddfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55a82874db8488fa2b6dc8b7c4c8197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7cd3e143a54fb5b900cf5943860ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text normalization: enabled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4245e19925ba42dfb5069d7d6f81941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe792316f504a0fa48f4cac34a5c5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a677eda40fc461ca2074ec543b17d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4af8143a66467c879ba69a845d9990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1484cc4a2ae46feb050c9a695f1dd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52533e321bcc4f589a5009c526c4413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2119701cba594db09a89dd8b26fdaaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.973601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5768\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5333    0.3256    0.4043       172\n",
      "           1     0.5645    0.2652    0.3608       132\n",
      "           2     0.5888    0.8506    0.6959       308\n",
      "\n",
      "    accuracy                         0.5768       612\n",
      "   macro avg     0.5622    0.4805    0.4870       612\n",
      "weighted avg     0.5680    0.5768    0.5417       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56  14 102]\n",
      " [ 16  35  81]\n",
      " [ 33  13 262]]\n",
      "✓ Saved best model (val_acc: 0.5768)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.713196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5703\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4866    0.5291    0.5070       172\n",
      "           1     0.5472    0.2197    0.3135       132\n",
      "           2     0.6156    0.7435    0.6735       308\n",
      "\n",
      "    accuracy                         0.5703       612\n",
      "   macro avg     0.5498    0.4974    0.4980       612\n",
      "weighted avg     0.5646    0.5703    0.5491       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 91  11  70]\n",
      " [ 30  29  73]\n",
      " [ 66  13 229]]\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.413332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5523\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4907    0.4593    0.4745       172\n",
      "           1     0.4184    0.3106    0.3565       132\n",
      "           2     0.6176    0.7078    0.6596       308\n",
      "\n",
      "    accuracy                         0.5523       612\n",
      "   macro avg     0.5089    0.4926    0.4969       612\n",
      "weighted avg     0.5389    0.5523    0.5422       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 79  20  73]\n",
      " [ 29  41  62]\n",
      " [ 53  37 218]]\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.280361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5523\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5676    0.3663    0.4452       172\n",
      "           1     0.3876    0.3788    0.3831       132\n",
      "           2     0.6048    0.7305    0.6618       308\n",
      "\n",
      "    accuracy                         0.5523       612\n",
      "   macro avg     0.5200    0.4919    0.4967       612\n",
      "weighted avg     0.5475    0.5523    0.5408       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 63  30  79]\n",
      " [ 14  50  68]\n",
      " [ 34  49 225]]\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.189948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5605\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4607    0.5116    0.4848       172\n",
      "           1     0.5278    0.2879    0.3725       132\n",
      "           2     0.6218    0.7045    0.6606       308\n",
      "\n",
      "    accuracy                         0.5605       612\n",
      "   macro avg     0.5368    0.5014    0.5060       612\n",
      "weighted avg     0.5562    0.5605    0.5491       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 88  13  71]\n",
      " [ 33  38  61]\n",
      " [ 70  21 217]]\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.132969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5507\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5040    0.3663    0.4242       172\n",
      "           1     0.4250    0.2576    0.3208       132\n",
      "           2     0.5897    0.7792    0.6713       308\n",
      "\n",
      "    accuracy                         0.5507       612\n",
      "   macro avg     0.5062    0.4677    0.4721       612\n",
      "weighted avg     0.5301    0.5507    0.5263       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 63  19  90]\n",
      " [ 21  34  77]\n",
      " [ 41  27 240]]\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.084700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5621\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5097    0.4593    0.4832       172\n",
      "           1     0.4815    0.1970    0.2796       132\n",
      "           2     0.5931    0.7760    0.6723       308\n",
      "\n",
      "    accuracy                         0.5621       612\n",
      "   macro avg     0.5281    0.4774    0.4783       612\n",
      "weighted avg     0.5456    0.5621    0.5344       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 79   8  85]\n",
      " [ 27  26  79]\n",
      " [ 49  20 239]]\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.062970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5376\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4897    0.4128    0.4479       172\n",
      "           1     0.4040    0.3030    0.3463       132\n",
      "           2     0.5924    0.7078    0.6450       308\n",
      "\n",
      "    accuracy                         0.5376       612\n",
      "   macro avg     0.4954    0.4745    0.4797       612\n",
      "weighted avg     0.5229    0.5376    0.5252       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 71  21  80]\n",
      " [ 22  40  70]\n",
      " [ 52  38 218]]\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.040545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5588\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5657    0.3256    0.4133       172\n",
      "           1     0.4697    0.2348    0.3131       132\n",
      "           2     0.5705    0.8279    0.6755       308\n",
      "\n",
      "    accuracy                         0.5588       612\n",
      "   macro avg     0.5353    0.4628    0.4673       612\n",
      "weighted avg     0.5474    0.5588    0.5236       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56  13 103]\n",
      " [ 12  31  89]\n",
      " [ 31  22 255]]\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.029421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 0.5539\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5164    0.3663    0.4286       172\n",
      "           1     0.4231    0.2500    0.3143       132\n",
      "           2     0.5898    0.7890    0.6750       308\n",
      "\n",
      "    accuracy                         0.5539       612\n",
      "   macro avg     0.5098    0.4684    0.4726       612\n",
      "weighted avg     0.5332    0.5539    0.5279       612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 63  20  89]\n",
      " [ 19  33  80]\n",
      " [ 40  25 243]]\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/1348239496.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Use parse_args([]) for notebook run without CLI arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_48/1348239496.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded model from epoch {ckpt.get('epoch', '?')} with val_acc: {ckpt.get('val_acc', 0):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/dataset5\")\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from normalizer import normalize\n",
    "\n",
    "\n",
    "import timm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text or pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, tokenizer, max_length=128, image_size=224,\n",
    "                 use_normalizer=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.image_size = image_size\n",
    "        self.use_normalizer = use_normalizer\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        img_path = self.images_dir / row['image_file_name']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            # fallback black image\n",
    "            img = Image.new('RGB', (self.image_size, self.image_size), color=(0, 0, 0))\n",
    "        img = self.transform(img)\n",
    "\n",
    "        text = clean_text(row.get('text', \"\"))\n",
    "\n",
    "        if self.use_normalizer and text:\n",
    "            try:\n",
    "                text = normalize(text)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        tok = self.tokenizer(text,\n",
    "                             truncation=True,\n",
    "                             padding='max_length',\n",
    "                             max_length=self.max_length,\n",
    "                             return_tensors='pt')\n",
    "        input_ids = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "\n",
    "        label = int(row['label'])\n",
    "        return {\n",
    "            'image': img,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([b['image'] for b in batch])\n",
    "    input_ids = torch.stack([b['input_ids'] for b in batch])\n",
    "    attention_mask = torch.stack([b['attention_mask'] for b in batch])\n",
    "    labels = torch.stack([b['label'] for b in batch])\n",
    "    texts = [b['text'] for b in batch]\n",
    "    return {\n",
    "        'image': images,\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels,\n",
    "        'texts': texts\n",
    "    }\n",
    "\n",
    "\n",
    "class MultimodalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    ViT (timm) + SentenceTransformer multimodal classifier.\n",
    "    If `text_model` is a sentence-transformers name -> use SentenceTransformer.\n",
    "    Otherwise it will try to load an AutoModel (e.g., BanglishBERT).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text_model: str, text_feat_dim: int, num_labels: int,\n",
    "                 freeze_text=False, freeze_image=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.text_model_name = text_model\n",
    "        self.use_sentence_transformer = \"sentence-transformers\" in text_model\n",
    "\n",
    "        # TEXT ENCODER\n",
    "        if self.use_sentence_transformer:\n",
    "            # SentenceTransformer loads a model and provides .encode(...)\n",
    "            self.text_encoder = SentenceTransformer(text_model)\n",
    "            raw_text_dim = self.text_encoder.get_sentence_embedding_dimension()\n",
    "        else:\n",
    "            # fallback to huggingface AutoModel\n",
    "            self.text_encoder = AutoModel.from_pretrained(text_model)\n",
    "            raw_text_dim = self.text_encoder.config.hidden_size\n",
    "\n",
    "        if freeze_text:\n",
    "            for p in self.text_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # Project text embedding into a 512-dim common space\n",
    "        self.text_proj = nn.Linear(raw_text_dim, 512)\n",
    "\n",
    "        # IMAGE ENCODER (ViT via timm). Remove classification head (num_classes=0)\n",
    "        self.image_encoder = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=0)\n",
    "        image_feat_dim = self.image_encoder.num_features if hasattr(self.image_encoder, \"num_features\") else 768\n",
    "        if freeze_image:\n",
    "            for p in self.image_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.image_proj = nn.Linear(image_feat_dim, 512)\n",
    "\n",
    "        # classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 + 512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, texts=None, input_ids=None, attention_mask=None):\n",
    "        # images -> [B, 3, H, W]\n",
    "        img_feat = self.image_encoder(images)           \n",
    "        img_feat = self.image_proj(img_feat)            \n",
    "\n",
    "        # text encoding:\n",
    "        if self.use_sentence_transformer:\n",
    "            \n",
    "            if texts is None:\n",
    "                raise ValueError(\"texts must be provided when using SentenceTransformer as text_model\")\n",
    "            \n",
    "            txt_feat = self.text_encoder.encode(texts, convert_to_tensor=True)\n",
    "            if isinstance(txt_feat, torch.Tensor):\n",
    "                txt_feat = txt_feat.to(img_feat.device)\n",
    "            else:\n",
    "                \n",
    "                txt_feat = torch.tensor(np.asarray(txt_feat), dtype=torch.float32, device=img_feat.device)\n",
    "        else:\n",
    "            \n",
    "            assert input_ids is not None and attention_mask is not None, \"input_ids/attention_mask required for AutoModel text encoder\"\n",
    "            text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            if hasattr(text_out, \"pooler_output\") and text_out.pooler_output is not None:\n",
    "                txt_feat = text_out.pooler_output\n",
    "            else:\n",
    "                last_hidden = text_out.last_hidden_state\n",
    "                mask = attention_mask.unsqueeze(-1).float()\n",
    "                summed = (last_hidden * mask).sum(1)\n",
    "                denom = mask.sum(1).clamp(min=1e-9)\n",
    "                txt_feat = summed / denom\n",
    "\n",
    "        txt_feat = self.text_proj(txt_feat)            # (B, 512)\n",
    "\n",
    "        fused = torch.cat([img_feat, txt_feat], dim=1)  # (B, 1024)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def find_discrepancies(df, images_dir):\n",
    "    images_dir = Path(images_dir)\n",
    "    referenced = set(df['image_file_name'].astype(str).tolist())\n",
    "    actual = set([p.name for p in images_dir.glob('*') if p.is_file()])\n",
    "    missing = sorted(list(referenced - actual))\n",
    "    orphan = sorted(list(actual - referenced))\n",
    "    return missing, orphan\n",
    "\n",
    "\n",
    "def prepare_dataframe(path, images_dir, drop_label_value=2):\n",
    "    df = pd.read_excel(path)\n",
    "    assert 'image_file_name' in df.columns and 'text' in df.columns and 'label' in df.columns, \\\n",
    "        \"metadata.xlsx must contain columns: image_file_name, text, label\"\n",
    "\n",
    "    df = df[df['label'] != drop_label_value].copy()\n",
    "    df['image_file_name'] = df['image_file_name'].astype(str).str.strip()\n",
    "\n",
    "    missing, orphan = find_discrepancies(df, images_dir)\n",
    "    if missing:\n",
    "        print(f\"Missing images for {len(missing)} metadata entries\")\n",
    "        df = df[~df['image_file_name'].isin(missing)].copy()\n",
    "\n",
    "    if orphan:\n",
    "        print(f\"Found {len(orphan)} orphan image files not in metadata (showing up to 20):\")\n",
    "        for o in orphan[:20]:\n",
    "            print(\"  -\", o)\n",
    "        if len(orphan) > 20:\n",
    "            print(\"  ... and more\")\n",
    "\n",
    "    unique_labels = sorted(df['label'].unique().tolist())\n",
    "    label_map = {orig: idx for idx, orig in enumerate(unique_labels)}\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "    print(\"Label mapping:\", label_map)\n",
    "    return df, orphan, label_map\n",
    "\n",
    "\n",
    "def compute_class_weights(df, power=0.5):\n",
    "    counts = df['label'].value_counts().sort_index().values\n",
    "    weights = (1.0 / counts) ** power\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    sample_weights = df['label'].map(lambda x: weights[x]).values\n",
    "    return sample_weights\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(dataloader, desc=\"Train\", leave=False):\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        texts = batch['texts']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images=images, texts=texts, input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, label_map):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for batch in tqdm(dataloader, desc=\"Eval\", leave=False):\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        texts = batch['texts']\n",
    "\n",
    "        logits = model(images=images, texts=texts, input_ids=input_ids, attention_mask=attention_mask)\n",
    "        batch_preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()\n",
    "        batch_trues = labels.cpu().numpy().tolist()\n",
    "        preds.extend(batch_preds)\n",
    "        trues.extend(batch_trues)\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    report = classification_report(trues, preds, digits=4)\n",
    "    cm = confusion_matrix(trues, preds)\n",
    "    return acc, report, trues, preds, cm\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    df, orphan_files, label_map = prepare_dataframe(args.data, args.images_dir, drop_label_value=2)\n",
    "\n",
    "    if args.delete_orphans and orphan_files:\n",
    "        for fname in orphan_files:\n",
    "            p = Path(args.images_dir) / fname\n",
    "            try:\n",
    "                p.unlink()\n",
    "            except Exception as e:\n",
    "                print(\"Could not delete:\", p, e)\n",
    "        print(\"Deleted orphans.\")\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=args.test_size, stratify=df['label'], random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=args.val_size, stratify=train_df['label'], random_state=42)\n",
    "    print(f\"Train / Val / Test sizes: {len(train_df)} / {len(val_df)} / {len(test_df)}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.text_model)\n",
    "\n",
    "    use_normalizer = not args.disable_normalizer\n",
    "    print(f\"Text normalization: {'enabled' if use_normalizer else 'disabled'}\")\n",
    "\n",
    "    train_dataset = MemeDataset(train_df, args.images_dir, tokenizer,\n",
    "                                max_length=args.max_length, image_size=args.image_size,\n",
    "                                use_normalizer=use_normalizer)\n",
    "    val_dataset = MemeDataset(val_df, args.images_dir, tokenizer,\n",
    "                              max_length=args.max_length, image_size=args.image_size,\n",
    "                              use_normalizer=use_normalizer)\n",
    "    test_dataset = MemeDataset(test_df, args.images_dir, tokenizer,\n",
    "                               max_length=args.max_length, image_size=args.image_size,\n",
    "                               use_normalizer=use_normalizer)\n",
    "\n",
    "    sample_weights = compute_class_weights(train_df, power=args.weight_power)\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=sampler,\n",
    "                              collate_fn=collate_fn, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                            collate_fn=collate_fn, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                             collate_fn=collate_fn, num_workers=0, pin_memory=True)\n",
    "\n",
    "    num_labels = len(label_map)\n",
    "    model = MultimodalClassifier(text_model=args.text_model,\n",
    "                                 text_feat_dim=args.text_feat_dim,\n",
    "                                 num_labels=num_labels,\n",
    "                                 freeze_text=args.freeze_text,\n",
    "                                 freeze_image=args.freeze_image)\n",
    "    model.to(device)\n",
    "\n",
    "    # loss, optimizer, scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * args.epochs\n",
    "    warmup_steps = int(0.1 * total_steps) if total_steps > 0 else 0\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{args.epochs}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, scheduler)\n",
    "        print(f\"Train loss: {train_loss:.6f}\")\n",
    "\n",
    "        val_acc, val_report, _, _, val_cm = evaluate(model, val_loader, device, label_map)\n",
    "        print(f\"Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "        print(\"Validation classification report:\")\n",
    "        print(val_report)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(val_cm)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'label_map': label_map,\n",
    "                'epoch': epoch,\n",
    "                'val_acc': val_acc\n",
    "            }, os.path.join(args.out_dir, \"best_model.pt\"))\n",
    "            print(f\"✓ Saved best model (val_acc: {val_acc:.4f})\")\n",
    "\n",
    "    # final evaluation on test\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*60)\n",
    "    ckpt_path = os.path.join(args.out_dir, \"best_model.pt\")\n",
    "    if os.path.exists(ckpt_path):\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "        print(f\"Loaded model from epoch {ckpt.get('epoch', '?')} with val_acc: {ckpt.get('val_acc', 0):.4f}\")\n",
    "    else:\n",
    "        print(\"No checkpoint found, using current model weights.\")\n",
    "\n",
    "    test_acc, test_report, trues, preds, test_cm = evaluate(model, test_loader, device, label_map)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(test_report)\n",
    "    print(\"\\nTest Confusion Matrix:\")\n",
    "    print(test_cm)\n",
    "\n",
    "    out = test_df.reset_index(drop=True).copy()\n",
    "    out['pred_idx'] = preds\n",
    "    inv_map = {v: k for k, v in label_map.items()}\n",
    "    out['pred_orig'] = out['pred_idx'].map(inv_map)\n",
    "    out['true_orig'] = out['label'].map(inv_map)\n",
    "    out.to_csv(os.path.join(args.out_dir, \"test_predictions.csv\"), index=False)\n",
    "    print(f\"\\nResults saved to {args.out_dir}/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', type=str, default='/kaggle/input/dataset5/metadata.xlsx')\n",
    "    parser.add_argument('--images_dir', type=str, default='/kaggle/input/dataset5/images')\n",
    "    parser.add_argument('--out_dir', type=str, default='/kaggle/working/output')\n",
    "    parser.add_argument('--epochs', type=int, default=10)            \n",
    "    parser.add_argument('--batch_size', type=int, default=10)        \n",
    "    parser.add_argument('--lr', type=float, default=2e-5)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.005)\n",
    "    \n",
    "    parser.add_argument('--text_model', type=str,\n",
    "                        default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    parser.add_argument('--max_length', type=int, default=64)\n",
    "    parser.add_argument('--image_size', type=int, default=224)\n",
    "    parser.add_argument('--val_size', type=float, default=0.1)\n",
    "    parser.add_argument('--test_size', type=float, default=0.1)\n",
    "    parser.add_argument('--text_feat_dim', type=int, default=768)   \n",
    "    parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "    parser.add_argument('--dropout', type=float, default=0.2)\n",
    "    parser.add_argument('--patience', type=int, default=7)\n",
    "    parser.add_argument('--weight_power', type=float, default=0.5)\n",
    "    parser.add_argument('--freeze_text', action='store_true')\n",
    "    parser.add_argument('--freeze_image', action='store_true')\n",
    "    parser.add_argument('--delete-orphans', action='store_true')\n",
    "    parser.add_argument('--disable-normalizer', action='store_true')\n",
    "    parser.add_argument('--augment', action='store_true')\n",
    "    parser.add_argument('--verbose', action='store_true')\n",
    "\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8806576,
     "sourceId": 13828006,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
